{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb081840",
   "metadata": {},
   "source": [
    "# Assignments 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c96c2e",
   "metadata": {},
   "source": [
    "# 1 Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6cb459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Target table not found.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to handle exceptions and fetch HTML content\n",
    "def fetch_html_content(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for non-200 status codes\n",
    "        return response.content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from {url}:\", e)\n",
    "        return None\n",
    "\n",
    "# Function to scrape video data from the HTML content\n",
    "def scrape_video_data(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Target the correct table with a more specific selector\n",
    "    table = soup.find('table', class_='wikitable sortable jquery-tablesorter')\n",
    "    if not table:\n",
    "        print(\"Error: Target table not found.\")\n",
    "        return []\n",
    "\n",
    "    # Extract data from table rows\n",
    "    video_data = []\n",
    "    for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) == 5:\n",
    "            rank = cells[0].text.strip()\n",
    "            name = cells[1].find('a').text.strip()\n",
    "            artist = cells[2].text.strip()\n",
    "            upload_date = cells[3].text.strip()\n",
    "            views = cells[4].text.strip().replace(\",\", \"\")  # Remove commas from views\n",
    "            video_data.append({\n",
    "                \"rank\": rank,\n",
    "                \"name\": name,\n",
    "                \"artist\": artist,\n",
    "                \"upload_date\": upload_date,\n",
    "                \"views\": views\n",
    "            })\n",
    "    return video_data\n",
    "\n",
    "# Main execution\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "html_content = fetch_html_content(url)\n",
    "if html_content:\n",
    "    video_data = scrape_video_data(html_content)\n",
    "    print(video_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b950036",
   "metadata": {},
   "source": [
    "# 2 Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9850e938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to international fixture page not found\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.bcci.tv/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the link to the international fixture page\n",
    "fixture_link = soup.find(\"a\", href=\"/international/fixtures\")\n",
    "\n",
    "# Check if the link is not None\n",
    "if fixture_link is not None:\n",
    "    # Navigate to the international fixture page\n",
    "    response = requests.get(url + fixture_link[\"href\"])\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the list of fixtures\n",
    "    fixtures = soup.find_all(\"div\", class_=\"fixture__format-strip\")\n",
    "\n",
    "    # Loop through each fixture and extract the details\n",
    "    for fixture in fixtures:\n",
    "        series = fixture.find(\"span\", class_=\"u-unskewed-text\").text.strip()\n",
    "        place = fixture.find(\"p\", class_=\"fixture__additional-info\").text.strip()\n",
    "        date = fixture.find(\"span\", class_=\"fixture__date\").text.strip()\n",
    "        time = fixture.find(\"span\", class_=\"fixture__time\").text.strip()\n",
    "        print(f\"Series: **{series}**, Place: **{place}**, Date: **{date}**, Time: **{time}**\")\n",
    "else:\n",
    "    print(\"Link to international fixture page not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714dd336",
   "metadata": {},
   "source": [
    "# 3 Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975c5c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to economy page not found\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://statisticstimes.com/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the link to the economy page\n",
    "economy_link = soup.find(\"a\", href=\"/economy\")\n",
    "\n",
    "# Check if the link is not None\n",
    "if economy_link is not None:\n",
    "    # Navigate to the economy page\n",
    "    response = requests.get(url + economy_link[\"href\"])\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the link to the State-wise GDP page\n",
    "    gdp_link = soup.find(\"a\", href=\"/economy/gdp-of-indian-states\")\n",
    "\n",
    "    # Check if the link is not None\n",
    "    if gdp_link is not None:\n",
    "        # Navigate to the State-wise GDP page\n",
    "        response = requests.get(url + gdp_link[\"href\"])\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Find the table containing the GDP details\n",
    "        table = soup.find(\"table\")\n",
    "\n",
    "        # Extract the rows of the table\n",
    "        rows = table.find_all(\"tr\")\n",
    "\n",
    "        # Loop through each row and extract the GDP details\n",
    "        for row in rows[1:]:\n",
    "            columns = row.find_all(\"td\")\n",
    "            rank = columns[0].text.strip()\n",
    "            state = columns[1].text.strip()\n",
    "            gdp_18_19 = columns[2].text.strip()\n",
    "            gdp_19_20 = columns[3].text.strip()\n",
    "            share_18_19 = columns[4].text.strip()\n",
    "            gdp_dollar_billion = columns[5].text.strip()\n",
    "            print(f\"Rank: **{rank}**, State: **{state}**, GSDP(18-19): **{gdp_18_19}**, GSDP(19-20): **{gdp_19_20}**, Share(18-19): **{share_18_19}**, GDP($ billion): **{gdp_dollar_billion}**\")\n",
    "    else:\n",
    "        print(\"Link to State-wise GDP page not found\")\n",
    "else:\n",
    "    print(\"Link to economy page not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a94a28",
   "metadata": {},
   "source": [
    "# 4 Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b052fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **TypeScript**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **C**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **Python**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **TypeScript**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **Java**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **Dart**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **No language found**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **JavaScript**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **JavaScript**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: ****, Language used: **TypeScript**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **JavaScript**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **No language found**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **Go**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **No language found**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **TypeScript**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **TypeScript**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **Python**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **PHP**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **C**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **TypeScript**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **C**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **No language found**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **Java**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **HTML**\n",
      "Repository title: **No title found**, Repository description: **No description found**, Contributors count: **No contributors found**, Language used: **TypeScript**\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://github.com/trending\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the list of trending repositories\n",
    "trending_repos = soup.find_all(\"article\", class_=\"Box-row\")\n",
    "\n",
    "# Loop through each repository and extract the details\n",
    "for repo in trending_repos:\n",
    "    if repo.find(\"h1\", class_=\"h3 lh-condensed\") is not None:\n",
    "        repo_title = repo.find(\"h1\", class_=\"h3 lh-condensed\").text.strip()\n",
    "    else:\n",
    "        repo_title = \"No title found\"\n",
    "    if repo.find(\"p\", class_=\"col-9 color-text-secondary my-1 pr-4\") is not None:\n",
    "        repo_description = repo.find(\"p\", class_=\"col-9 color-text-secondary my-1 pr-4\").text.strip()\n",
    "    else:\n",
    "        repo_description = \"No description found\"\n",
    "    if repo.find(\"a\", href=lambda href: href and \"contributors\" in href) is not None:\n",
    "        contributors_count = repo.find(\"a\", href=lambda href: href and \"contributors\" in href).text.strip()\n",
    "    else:\n",
    "        contributors_count = \"No contributors found\"\n",
    "    if repo.find(\"span\", itemprop=\"programmingLanguage\") is not None:\n",
    "        language_used = repo.find(\"span\", itemprop=\"programmingLanguage\").text.strip()\n",
    "    else:\n",
    "        language_used = \"No language found\"\n",
    "    print(f\"Repository title: **{repo_title}**, Repository description: **{repo_description}**, Contributors count: **{contributors_count}**, Language used: **{language_used}**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38373371",
   "metadata": {},
   "source": [
    "# 5 Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7cb0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chart not found\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.billboard.com/charts/hot-100\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the chart containing the song details\n",
    "chart = soup.find(\"div\", class_=\"chart-list container\")\n",
    "\n",
    "# Check if the chart is not None\n",
    "if chart is not None:\n",
    "    # Extract the songs from the chart\n",
    "    songs = chart.find_all(\"li\")\n",
    "\n",
    "    # Loop through each song and extract the details\n",
    "    for song in songs:\n",
    "        song_name = song.find(\"span\", class_=\"chart-element__information__song\").text.strip()\n",
    "        artist_name = song.find(\"span\", class_=\"chart-element__information__artist\").text.strip()\n",
    "        last_week_rank = song.find(\"span\", class_=\"chart-element__meta text--center color--secondary text--last\").text.strip()\n",
    "        peak_rank = song.find(\"span\", class_=\"chart-element__meta text--center color--secondary text--peak\").text.strip()\n",
    "        weeks_on_board = song.find(\"span\", class_=\"chart-element__meta text--center color--secondary text--week\").text.strip()\n",
    "        print(f\"Song name: **{song_name}**, Artist name: **{artist_name}**, Last week rank: **{last_week_rank}**, Peak rank: **{peak_rank}**, Weeks on board: **{weeks_on_board}**\")\n",
    "else:\n",
    "    print(\"Chart not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5561cd",
   "metadata": {},
   "source": [
    "# 6 Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e33f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid row\n",
      "Book name: **Da Vinci Code,The**, Author name: **Brown, Dan**, Volumes sold: **5,094,805**, Publisher: **Transworld**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **Harry Potter and the Deathly Hallows**, Author name: **Rowling, J.K.**, Volumes sold: **4,475,152**, Publisher: **Bloomsbury**, Genre: **Children's Fiction**\n",
      "Book name: **Harry Potter and the Philosopher's Stone**, Author name: **Rowling, J.K.**, Volumes sold: **4,200,654**, Publisher: **Bloomsbury**, Genre: **Children's Fiction**\n",
      "Book name: **Harry Potter and the Order of the Phoenix**, Author name: **Rowling, J.K.**, Volumes sold: **4,179,479**, Publisher: **Bloomsbury**, Genre: **Children's Fiction**\n",
      "Book name: **Fifty Shades of Grey**, Author name: **James, E. L.**, Volumes sold: **3,758,936**, Publisher: **Random House**, Genre: **Romance & Sagas**\n",
      "Book name: **Harry Potter and the Goblet of Fire**, Author name: **Rowling, J.K.**, Volumes sold: **3,583,215**, Publisher: **Bloomsbury**, Genre: **Children's Fiction**\n",
      "Book name: **Harry Potter and the Chamber of Secrets**, Author name: **Rowling, J.K.**, Volumes sold: **3,484,047**, Publisher: **Bloomsbury**, Genre: **Children's Fiction**\n",
      "Book name: **Harry Potter and the Prisoner of Azkaban**, Author name: **Rowling, J.K.**, Volumes sold: **3,377,906**, Publisher: **Bloomsbury**, Genre: **Children's Fiction**\n",
      "Book name: **Angels and Demons**, Author name: **Brown, Dan**, Volumes sold: **3,193,946**, Publisher: **Transworld**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **Harry Potter and the Half-blood Prince:Children's Edition**, Author name: **Rowling, J.K.**, Volumes sold: **2,950,264**, Publisher: **Bloomsbury**, Genre: **Children's Fiction**\n",
      "Book name: **Fifty Shades Darker**, Author name: **James, E. L.**, Volumes sold: **2,479,784**, Publisher: **Random House**, Genre: **Romance & Sagas**\n",
      "Book name: **Twilight**, Author name: **Meyer, Stephenie**, Volumes sold: **2,315,405**, Publisher: **Little, Brown Book**, Genre: **Young Adult Fiction**\n",
      "Book name: **Girl with the Dragon Tattoo,The:Millennium Trilogy**, Author name: **Larsson, Stieg**, Volumes sold: **2,233,570**, Publisher: **Quercus**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **Fifty Shades Freed**, Author name: **James, E. L.**, Volumes sold: **2,193,928**, Publisher: **Random House**, Genre: **Romance & Sagas**\n",
      "Book name: **Lost Symbol,The**, Author name: **Brown, Dan**, Volumes sold: **2,183,031**, Publisher: **Transworld**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **New Moon**, Author name: **Meyer, Stephenie**, Volumes sold: **2,152,737**, Publisher: **Little, Brown Book**, Genre: **Young Adult Fiction**\n",
      "Book name: **Deception Point**, Author name: **Brown, Dan**, Volumes sold: **2,062,145**, Publisher: **Transworld**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **Eclipse**, Author name: **Meyer, Stephenie**, Volumes sold: **2,052,876**, Publisher: **Little, Brown Book**, Genre: **Young Adult Fiction**\n",
      "Book name: **Lovely Bones,The**, Author name: **Sebold, Alice**, Volumes sold: **2,005,598**, Publisher: **Pan Macmillan**, Genre: **General & Literary Fiction**\n",
      "Book name: **Curious Incident of the Dog in the Night-time,The**, Author name: **Haddon, Mark**, Volumes sold: **1,979,552**, Publisher: **Random House**, Genre: **General & Literary Fiction**\n",
      "Book name: **Digital Fortress**, Author name: **Brown, Dan**, Volumes sold: **1,928,900**, Publisher: **Transworld**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **Short History of Nearly Everything,A**, Author name: **Bryson, Bill**, Volumes sold: **1,852,919**, Publisher: **Transworld**, Genre: **Popular Science**\n",
      "Book name: **Girl Who Played with Fire,The:Millennium Trilogy**, Author name: **Larsson, Stieg**, Volumes sold: **1,814,784**, Publisher: **Quercus**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **Breaking Dawn**, Author name: **Meyer, Stephenie**, Volumes sold: **1,787,118**, Publisher: **Little, Brown Book**, Genre: **Young Adult Fiction**\n",
      "Book name: **Very Hungry Caterpillar,The:The Very Hungry Caterpillar**, Author name: **Carle, Eric**, Volumes sold: **1,783,535**, Publisher: **Penguin**, Genre: **Picture Books**\n",
      "Book name: **Gruffalo,The**, Author name: **Donaldson, Julia**, Volumes sold: **1,781,269**, Publisher: **Pan Macmillan**, Genre: **Picture Books**\n",
      "Book name: **Jamie's 30-Minute Meals**, Author name: **Oliver, Jamie**, Volumes sold: **1,743,266**, Publisher: **Penguin**, Genre: **Food & Drink: General**\n",
      "Book name: **Kite Runner,The**, Author name: **Hosseini, Khaled**, Volumes sold: **1,629,119**, Publisher: **Bloomsbury**, Genre: **General & Literary Fiction**\n",
      "Book name: **One Day**, Author name: **Nicholls, David**, Volumes sold: **1,616,068**, Publisher: **Hodder & Stoughton**, Genre: **General & Literary Fiction**\n",
      "Book name: **Thousand Splendid Suns,A**, Author name: **Hosseini, Khaled**, Volumes sold: **1,583,992**, Publisher: **Bloomsbury**, Genre: **General & Literary Fiction**\n",
      "Book name: **Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy**, Author name: **Larsson, Stieg**, Volumes sold: **1,555,135**, Publisher: **Quercus**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **Time Traveler's Wife,The**, Author name: **Niffenegger, Audrey**, Volumes sold: **1,546,886**, Publisher: **Random House**, Genre: **General & Literary Fiction**\n",
      "Book name: **Atonement**, Author name: **McEwan, Ian**, Volumes sold: **1,539,428**, Publisher: **Random House**, Genre: **General & Literary Fiction**\n",
      "Book name: **Bridget Jones's Diary:A Novel**, Author name: **Fielding, Helen**, Volumes sold: **1,508,205**, Publisher: **Pan Macmillan**, Genre: **General & Literary Fiction**\n",
      "Book name: **World According to Clarkson,The**, Author name: **Clarkson, Jeremy**, Volumes sold: **1,489,403**, Publisher: **Penguin**, Genre: **Humour: Collections & General**\n",
      "Book name: **Captain Corelli's Mandolin**, Author name: **Bernieres, Louis de**, Volumes sold: **1,352,318**, Publisher: **Random House**, Genre: **General & Literary Fiction**\n",
      "Book name: **Sound of Laughter,The**, Author name: **Kay, Peter**, Volumes sold: **1,310,207**, Publisher: **Random House**, Genre: **Autobiography: General**\n",
      "Book name: **Life of Pi**, Author name: **Martel, Yann**, Volumes sold: **1,310,176**, Publisher: **Canongate**, Genre: **General & Literary Fiction**\n",
      "Book name: **Billy Connolly**, Author name: **Stephenson, Pamela**, Volumes sold: **1,231,957**, Publisher: **HarperCollins**, Genre: **Biography: The Arts**\n",
      "Book name: **Child Called It,A**, Author name: **Pelzer, Dave**, Volumes sold: **1,217,712**, Publisher: **Orion**, Genre: **Autobiography: General**\n",
      "Book name: **Gruffalo's Child,The**, Author name: **Donaldson, Julia**, Volumes sold: **1,208,711**, Publisher: **Pan Macmillan**, Genre: **Picture Books**\n",
      "Book name: **Angela's Ashes:A Memoir of a Childhood**, Author name: **McCourt, Frank**, Volumes sold: **1,204,058**, Publisher: **HarperCollins**, Genre: **Autobiography: General**\n",
      "Book name: **Birdsong**, Author name: **Faulks, Sebastian**, Volumes sold: **1,184,967**, Publisher: **Random House**, Genre: **General & Literary Fiction**\n",
      "Book name: **Northern Lights:His Dark Materials S.**, Author name: **Pullman, Philip**, Volumes sold: **1,181,503**, Publisher: **Scholastic Ltd.**, Genre: **Young Adult Fiction**\n",
      "Book name: **Labyrinth**, Author name: **Mosse, Kate**, Volumes sold: **1,181,093**, Publisher: **Orion**, Genre: **General & Literary Fiction**\n",
      "Book name: **Harry Potter and the Half-blood Prince**, Author name: **Rowling, J.K.**, Volumes sold: **1,153,181**, Publisher: **Bloomsbury**, Genre: **Science Fiction & Fantasy**\n",
      "Book name: **Help,The**, Author name: **Stockett, Kathryn**, Volumes sold: **1,132,336**, Publisher: **Penguin**, Genre: **General & Literary Fiction**\n",
      "Book name: **Man and Boy**, Author name: **Parsons, Tony**, Volumes sold: **1,130,802**, Publisher: **HarperCollins**, Genre: **General & Literary Fiction**\n",
      "Book name: **Memoirs of a Geisha**, Author name: **Golden, Arthur**, Volumes sold: **1,126,337**, Publisher: **Random House**, Genre: **General & Literary Fiction**\n",
      "Book name: **No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.**, Author name: **McCall Smith, Alexander**, Volumes sold: **1,115,549**, Publisher: **Little, Brown Book**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **Island,The**, Author name: **Hislop, Victoria**, Volumes sold: **1,108,328**, Publisher: **Headline**, Genre: **General & Literary Fiction**\n",
      "Book name: **PS, I Love You**, Author name: **Ahern, Cecelia**, Volumes sold: **1,107,379**, Publisher: **HarperCollins**, Genre: **General & Literary Fiction**\n",
      "Book name: **You are What You Eat:The Plan That Will Change Your Life**, Author name: **McKeith, Gillian**, Volumes sold: **1,104,403**, Publisher: **Penguin**, Genre: **Fitness & Diet**\n",
      "Book name: **Shadow of the Wind,The**, Author name: **Zafon, Carlos Ruiz**, Volumes sold: **1,092,349**, Publisher: **Orion**, Genre: **General & Literary Fiction**\n",
      "Book name: **Tales of Beedle the Bard,The**, Author name: **Rowling, J.K.**, Volumes sold: **1,090,847**, Publisher: **Bloomsbury**, Genre: **Children's Fiction**\n",
      "Book name: **Broker,The**, Author name: **Grisham, John**, Volumes sold: **1,087,262**, Publisher: **Random House**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P**, Author name: **Atkins, Robert C.**, Volumes sold: **1,054,196**, Publisher: **Random House**, Genre: **Fitness & Diet**\n",
      "Book name: **Subtle Knife,The:His Dark Materials S.**, Author name: **Pullman, Philip**, Volumes sold: **1,037,160**, Publisher: **Scholastic Ltd.**, Genre: **Young Adult Fiction**\n",
      "Book name: **Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation**, Author name: **Truss, Lynne**, Volumes sold: **1,023,688**, Publisher: **Profile Books Group**, Genre: **Usage & Writing Guides**\n",
      "Book name: **Delia's How to Cook:(Bk.1)**, Author name: **Smith, Delia**, Volumes sold: **1,015,956**, Publisher: **Random House**, Genre: **Food & Drink: General**\n",
      "Book name: **Chocolat**, Author name: **Harris, Joanne**, Volumes sold: **1,009,873**, Publisher: **Transworld**, Genre: **General & Literary Fiction**\n",
      "Book name: **Boy in the Striped Pyjamas,The**, Author name: **Boyne, John**, Volumes sold: **1,004,414**, Publisher: **Random House Childrens Books G**, Genre: **Young Adult Fiction**\n",
      "Book name: **My Sister's Keeper**, Author name: **Picoult, Jodi**, Volumes sold: **1,003,780**, Publisher: **Hodder & Stoughton**, Genre: **General & Literary Fiction**\n",
      "Book name: **Amber Spyglass,The:His Dark Materials S.**, Author name: **Pullman, Philip**, Volumes sold: **1,002,314**, Publisher: **Scholastic Ltd.**, Genre: **Young Adult Fiction**\n",
      "Book name: **To Kill a Mockingbird**, Author name: **Lee, Harper**, Volumes sold: **998,213**, Publisher: **Random House**, Genre: **General & Literary Fiction**\n",
      "Book name: **Men are from Mars, Women are from Venus:A Practical Guide for Improvin**, Author name: **Gray, John**, Volumes sold: **992,846**, Publisher: **HarperCollins**, Genre: **Popular Culture & Media: General Interest**\n",
      "Book name: **Dear Fatty**, Author name: **French, Dawn**, Volumes sold: **986,753**, Publisher: **Random House**, Genre: **Autobiography: The Arts**\n",
      "Book name: **Short History of Tractors in Ukrainian,A**, Author name: **Lewycka, Marina**, Volumes sold: **986,115**, Publisher: **Penguin**, Genre: **General & Literary Fiction**\n",
      "Book name: **Hannibal**, Author name: **Harris, Thomas**, Volumes sold: **970,509**, Publisher: **Random House**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **Lord of the Rings,The**, Author name: **Tolkien, J. R. R.**, Volumes sold: **967,466**, Publisher: **HarperCollins**, Genre: **Science Fiction & Fantasy**\n",
      "Book name: **Stupid White Men:...and Other Sorry Excuses for the State of the Natio**, Author name: **Moore, Michael**, Volumes sold: **963,353**, Publisher: **Penguin**, Genre: **Current Affairs & Issues**\n",
      "Book name: **Interpretation of Murder,The**, Author name: **Rubenfeld, Jed**, Volumes sold: **962,515**, Publisher: **Headline**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **Sharon Osbourne Extreme:My Autobiography**, Author name: **Osbourne, Sharon**, Volumes sold: **959,496**, Publisher: **Little, Brown Book**, Genre: **Autobiography: The Arts**\n",
      "Book name: **Alchemist,The:A Fable About Following Your Dream**, Author name: **Coelho, Paulo**, Volumes sold: **956,114**, Publisher: **HarperCollins**, Genre: **General & Literary Fiction**\n",
      "Book name: **At My Mother's Knee ...:and Other Low Joints**, Author name: **O'Grady, Paul**, Volumes sold: **945,640**, Publisher: **Transworld**, Genre: **Autobiography: The Arts**\n",
      "Book name: **Notes from a Small Island**, Author name: **Bryson, Bill**, Volumes sold: **931,312**, Publisher: **Transworld**, Genre: **Travel Writing**\n",
      "Book name: **Return of the Naked Chef,The**, Author name: **Oliver, Jamie**, Volumes sold: **925,425**, Publisher: **Penguin**, Genre: **Food & Drink: General**\n",
      "Book name: **Bridget Jones: The Edge of Reason**, Author name: **Fielding, Helen**, Volumes sold: **924,695**, Publisher: **Pan Macmillan**, Genre: **General & Literary Fiction**\n",
      "Book name: **Jamie's Italy**, Author name: **Oliver, Jamie**, Volumes sold: **906,968**, Publisher: **Penguin**, Genre: **National & Regional Cuisine**\n",
      "Book name: **I Can Make You Thin**, Author name: **McKenna, Paul**, Volumes sold: **905,086**, Publisher: **Transworld**, Genre: **Fitness & Diet**\n",
      "Book name: **Down Under**, Author name: **Bryson, Bill**, Volumes sold: **890,847**, Publisher: **Transworld**, Genre: **Travel Writing**\n",
      "Book name: **Summons,The**, Author name: **Grisham, John**, Volumes sold: **869,671**, Publisher: **Random House**, Genre: **Crime, Thriller & Adventure**\n",
      "Book name: **Small Island**, Author name: **Levy, Andrea**, Volumes sold: **869,659**, Publisher: **Headline**, Genre: **General & Literary Fiction**\n",
      "Book name: **Nigella Express**, Author name: **Lawson, Nigella**, Volumes sold: **862,602**, Publisher: **Random House**, Genre: **Food & Drink: General**\n",
      "Book name: **Brick Lane**, Author name: **Ali, Monica**, Volumes sold: **856,540**, Publisher: **Transworld**, Genre: **General & Literary Fiction**\n",
      "Book name: **Memory Keeper's Daughter,The**, Author name: **Edwards, Kim**, Volumes sold: **845,858**, Publisher: **Penguin**, Genre: **General & Literary Fiction**\n",
      "Book name: **Room on the Broom**, Author name: **Donaldson, Julia**, Volumes sold: **842,535**, Publisher: **Pan Macmillan**, Genre: **Picture Books**\n",
      "Book name: **About a Boy**, Author name: **Hornby, Nick**, Volumes sold: **828,215**, Publisher: **Penguin**, Genre: **General & Literary Fiction**\n",
      "Book name: **My Booky Wook**, Author name: **Brand, Russell**, Volumes sold: **820,563**, Publisher: **Hodder & Stoughton**, Genre: **Autobiography: The Arts**\n",
      "Book name: **God Delusion,The**, Author name: **Dawkins, Richard**, Volumes sold: **816,907**, Publisher: **Transworld**, Genre: **Popular Science**\n",
      "Book name: **\"Beano\" Annual,The**, Author name: **0**, Volumes sold: **816,585**, Publisher: **D.C. Thomson**, Genre: **Children's Annuals**\n",
      "Book name: **White Teeth**, Author name: **Smith, Zadie**, Volumes sold: **815,586**, Publisher: **Penguin**, Genre: **General & Literary Fiction**\n",
      "Book name: **House at Riverton,The**, Author name: **Morton, Kate**, Volumes sold: **814,370**, Publisher: **Pan Macmillan**, Genre: **General & Literary Fiction**\n",
      "Book name: **Book Thief,The**, Author name: **Zusak, Markus**, Volumes sold: **809,641**, Publisher: **Transworld**, Genre: **General & Literary Fiction**\n",
      "Book name: **Nights of Rain and Stars**, Author name: **Binchy, Maeve**, Volumes sold: **808,900**, Publisher: **Orion**, Genre: **General & Literary Fiction**\n",
      "Book name: **Ghost,The**, Author name: **Harris, Robert**, Volumes sold: **807,311**, Publisher: **Random House**, Genre: **General & Literary Fiction**\n",
      "Book name: **Happy Days with the Naked Chef**, Author name: **Oliver, Jamie**, Volumes sold: **794,201**, Publisher: **Penguin**, Genre: **Food & Drink: General**\n",
      "Book name: **Hunger Games,The:Hunger Games Trilogy**, Author name: **Collins, Suzanne**, Volumes sold: **792,187**, Publisher: **Scholastic Ltd.**, Genre: **Young Adult Fiction**\n",
      "Book name: **Lost Boy,The:A Foster Child's Search for the Love of a Family**, Author name: **Pelzer, Dave**, Volumes sold: **791,507**, Publisher: **Orion**, Genre: **Biography: General**\n",
      "Book name: **Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours**, Author name: **Oliver, Jamie**, Volumes sold: **791,095**, Publisher: **Penguin**, Genre: **Food & Drink: General**\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the book details\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Extract the rows of the table\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "# Loop through each row and extract the book details\n",
    "for row in rows[1:]:\n",
    "    columns = row.find_all(\"td\")\n",
    "    if len(columns) >= 5:\n",
    "        book_name = columns[1].text.strip()\n",
    "        author_name = columns[2].text.strip()\n",
    "        volumes_sold = columns[3].text.strip()\n",
    "        publisher = columns[4].text.strip()\n",
    "        genre = columns[5].text.strip()\n",
    "        print(f\"Book name: **{book_name}**, Author name: **{author_name}**, Volumes sold: **{volumes_sold}**, Publisher: **{publisher}**, Genre: **{genre}**\")\n",
    "    else:\n",
    "        print(\"Invalid row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eb433d",
   "metadata": {},
   "source": [
    "# 7 Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7eaa7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data from https://www.imdb.com/list/ls095964455/: 404 Client Error:  for url: https://www.imdb.com/list/ls095964455/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to handle exceptions and fetch HTML content\n",
    "def fetch_html_content(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from {url}:\", e)\n",
    "        return None\n",
    "\n",
    "# Function to scrape series data from the HTML content\n",
    "def scrape_series_data(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Target the container of series entries\n",
    "    series_items = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "\n",
    "    # Extract data from each series item\n",
    "    series_data = []\n",
    "    for item in series_items:\n",
    "        title_info = item.find('div', class_='lister-item-content')\n",
    "        \n",
    "        # Extract name and year span\n",
    "        title = title_info.find('a', class_='lister-item-header').text.strip()\n",
    "        year_span = title_info.find('span', class_='lister-item-year').text.strip()\n",
    "\n",
    "        # Extract other details\n",
    "        genre = item.find('span', class_='genre').text.strip()\n",
    "        run_time = item.find('span', class_='runtime').text.strip()\n",
    "        ratings = item.find('span', class_='ratings-rating strong').text.strip()\n",
    "        votes = item.find('span', class_='ratings-count text-muted').text.strip()\n",
    "\n",
    "        series_data.append({\n",
    "            \"name\": title,\n",
    "            \"year_span\": year_span,\n",
    "            \"genre\": genre,\n",
    "            \"run_time\": run_time,\n",
    "            \"ratings\": ratings,\n",
    "            \"votes\": votes\n",
    "        })\n",
    "    return series_data\n",
    "\n",
    "# Main execution\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "html_content = fetch_html_content(url)\n",
    "if html_content:\n",
    "    series_data = scrape_series_data(html_content)\n",
    "    print(series_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1042e5bd",
   "metadata": {},
   "source": [
    "# 8 Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e056a92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to Show All Dataset page not found\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the link to the Show All Dataset page\n",
    "dataset_link = soup.find(\"a\", href=\"/ml/datasets.php\")\n",
    "\n",
    "# Check if the link is not None\n",
    "if dataset_link is not None:\n",
    "    # Navigate to the Show All Dataset page\n",
    "    response = requests.get(url + dataset_link[\"href\"])\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the table containing the dataset details\n",
    "    table = soup.find(\"table\")\n",
    "\n",
    "    # Extract the rows of the table\n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "    # Loop through each row and extract the dataset details\n",
    "    for row in rows[1:]:\n",
    "        columns = row.find_all(\"td\")\n",
    "        dataset_name = columns[0].text.strip()\n",
    "        data_type = columns[1].text.strip()\n",
    "        task = columns[2].text.strip()\n",
    "        attribute_type = columns[3].text.strip()\n",
    "        no_of_instances = columns[4].text.strip()\n",
    "        no_of_attributes = columns[5].text.strip()\n",
    "        year = columns[6].text.strip()\n",
    "        print(f\"Dataset name: **{dataset_name}**, Data type: **{data_type}**, Task: **{task}**, Attribute type: **{attribute_type}**, No of instances: **{no_of_instances}**, No of attributes: **{no_of_attributes}**, Year: **{year}**\")\n",
    "else:\n",
    "    print(\"Link to Show All Dataset page not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbcba1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
